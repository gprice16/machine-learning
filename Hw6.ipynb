{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1429e115-a3ca-4375-ae8c-75161f5315b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the dataset\n",
    "data_path = 'C:\\\\Users\\\\Gideon Price\\\\Downloads/Housing.csv'\n",
    "housing = pd.read_csv(data_path)\n",
    "housing.head()\n",
    "\n",
    "# Preprocessing data\n",
    "def binary(x):\n",
    "    return x.map({'no' : 0, 'yes' : 1})\n",
    "\n",
    "columns_to_convert = ['mainroad', 'guestroom', 'basement', 'hotwaterheating', 'prefarea', 'airconditioning']\n",
    "\n",
    "for column in columns_to_convert:\n",
    "    housing[column] = binary(housing[column])\n",
    "housing = housing.drop('furnishingstatus', axis=1)\n",
    "# Splitting the data into features and target\n",
    "x = housing[['area', 'bedrooms', 'bathrooms', 'stories', 'parking','mainroad', 'guestroom', 'basement', 'guestroom', 'hotwaterheating', 'basement', 'prefarea', 'airconditioning']].values\n",
    "y = housing['price'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10ee30b6-1708-4333-9eda-e4b786c084b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>area</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>stories</th>\n",
       "      <th>mainroad</th>\n",
       "      <th>guestroom</th>\n",
       "      <th>basement</th>\n",
       "      <th>hotwaterheating</th>\n",
       "      <th>airconditioning</th>\n",
       "      <th>parking</th>\n",
       "      <th>prefarea</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13300000</td>\n",
       "      <td>7420</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12250000</td>\n",
       "      <td>8960</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12250000</td>\n",
       "      <td>9960</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12215000</td>\n",
       "      <td>7500</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11410000</td>\n",
       "      <td>7420</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      price  area  bedrooms  bathrooms  stories  mainroad  guestroom  \\\n",
       "0  13300000  7420         4          2        3         1          0   \n",
       "1  12250000  8960         4          4        4         1          0   \n",
       "2  12250000  9960         3          2        2         1          0   \n",
       "3  12215000  7500         4          2        2         1          0   \n",
       "4  11410000  7420         4          1        2         1          1   \n",
       "\n",
       "   basement  hotwaterheating  airconditioning  parking  prefarea  \n",
       "0         0                0                1        2         1  \n",
       "1         0                0                1        3         0  \n",
       "2         1                0                0        2         1  \n",
       "3         1                0                1        3         1  \n",
       "4         1                0                1        2         0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69b81120-41bb-4d62-8489-02fc862ada45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 80/20 Train/Test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, train_size = 0.8, test_size=0.2, random_state=42)\n",
    "\n",
    "# Further split the training set into training and validation sets\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, train_size=0.8, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalizing the input data\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "x_val = scaler.transform(x_val)\n",
    "\n",
    "# Normalize output data\n",
    "y_train = scaler.fit_transform(y_train.reshape(-1, 1)).flatten()\n",
    "y_test = scaler.fit_transform(y_test.reshape(-1, 1)).flatten()\n",
    "y_val = scaler.transform(y_val.reshape(-1, 1)).flatten()\n",
    "\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "x_train = torch.tensor(x_train, dtype=torch.float32)\n",
    "x_test = torch.tensor(x_test, dtype=torch.float32)\n",
    "x_val = torch.tensor(x_val, dtype=torch.float32)\n",
    "y_train =  torch.tensor(y_train, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32)\n",
    "y_val = torch.tensor(y_val, dtype=torch.float32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50f43dec-faa8-4a2f-9b8c-3edd7a242825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the neural network model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.hidden = nn.Linear(x_train.shape[1], 32)\n",
    "        self.output = nn.Linear(32, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.hidden(x))\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n",
    "model = NeuralNetwork()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08f5065a-10a2-4cba-a869-5776eb095c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gideon Price\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:538: UserWarning: Using a target size (torch.Size([348])) that is different to the input size (torch.Size([348, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Gideon Price\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:538: UserWarning: Using a target size (torch.Size([88])) that is different to the input size (torch.Size([88, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [500/5000], Training Loss: 1.0001, Validation Loss: 0.6131\n",
      "Epoch [1000/5000], Training Loss: 1.0000, Validation Loss: 0.6132\n",
      "Epoch [1500/5000], Training Loss: 1.0000, Validation Loss: 0.6132\n",
      "Epoch [2000/5000], Training Loss: 1.0000, Validation Loss: 0.6132\n",
      "Epoch [2500/5000], Training Loss: 1.0000, Validation Loss: 0.6132\n",
      "Epoch [3000/5000], Training Loss: 1.0000, Validation Loss: 0.6132\n",
      "Epoch [3500/5000], Training Loss: 1.0000, Validation Loss: 0.6132\n",
      "Epoch [4000/5000], Training Loss: 1.0000, Validation Loss: 0.6131\n",
      "Epoch [4500/5000], Training Loss: 1.0000, Validation Loss: 0.6131\n",
      "Epoch [5000/5000], Training Loss: 1.0000, Validation Loss: 0.6131\n",
      "Test Loss: 1.0002\n",
      "tensor([[ 2.6534e-04],\n",
      "        [ 1.9009e-04],\n",
      "        [-6.3489e-04],\n",
      "        [-2.5724e-04],\n",
      "        [ 7.6701e-04],\n",
      "        [ 8.6565e-03],\n",
      "        [ 1.0800e-03],\n",
      "        [-7.9372e-03],\n",
      "        [-4.2408e-02],\n",
      "        [ 7.1701e-04],\n",
      "        [ 1.4599e-02],\n",
      "        [-4.6885e-04],\n",
      "        [-1.0195e-02],\n",
      "        [-6.4208e-04],\n",
      "        [-1.0535e-03],\n",
      "        [ 1.1861e-02],\n",
      "        [-5.6540e-03],\n",
      "        [ 2.6221e-03],\n",
      "        [-6.3825e-03],\n",
      "        [-7.9530e-04],\n",
      "        [-1.5504e-02],\n",
      "        [-1.8513e-02],\n",
      "        [-2.2456e-05],\n",
      "        [-6.2430e-03],\n",
      "        [-1.1019e-02],\n",
      "        [ 2.6793e-02],\n",
      "        [ 6.1827e-03],\n",
      "        [ 5.1536e-03],\n",
      "        [ 1.6581e-03],\n",
      "        [ 6.6175e-04],\n",
      "        [-7.1822e-03],\n",
      "        [-9.2013e-03],\n",
      "        [ 4.0087e-03],\n",
      "        [ 6.8699e-03],\n",
      "        [ 2.5623e-04],\n",
      "        [-2.5723e-03],\n",
      "        [ 1.1144e-02],\n",
      "        [ 2.2480e-02],\n",
      "        [ 4.7654e-03],\n",
      "        [-3.7205e-03],\n",
      "        [-1.2009e-03],\n",
      "        [-2.2334e-03],\n",
      "        [ 2.4137e-04],\n",
      "        [-1.0837e-03],\n",
      "        [ 1.2556e-03],\n",
      "        [-9.9740e-04],\n",
      "        [-4.4186e-04],\n",
      "        [ 2.2531e-03],\n",
      "        [-4.9229e-03],\n",
      "        [ 1.8235e-03],\n",
      "        [-3.2806e-03],\n",
      "        [ 2.4768e-04],\n",
      "        [-4.1380e-04],\n",
      "        [-2.3635e-02],\n",
      "        [ 1.3874e-02],\n",
      "        [ 4.6171e-05],\n",
      "        [ 2.6749e-02],\n",
      "        [-4.1726e-03],\n",
      "        [ 5.1372e-03],\n",
      "        [-2.5897e-04],\n",
      "        [ 2.3359e-02],\n",
      "        [ 9.3247e-03],\n",
      "        [ 1.6335e-02],\n",
      "        [-1.2023e-02],\n",
      "        [ 5.7038e-03],\n",
      "        [ 7.4894e-03],\n",
      "        [ 4.8306e-03],\n",
      "        [ 1.2971e-04],\n",
      "        [ 6.7941e-02],\n",
      "        [-6.1853e-03],\n",
      "        [ 6.2519e-03],\n",
      "        [ 1.0133e-02],\n",
      "        [ 2.8848e-03],\n",
      "        [ 6.7619e-03],\n",
      "        [ 6.2099e-03],\n",
      "        [-4.8981e-02],\n",
      "        [-2.1884e-03],\n",
      "        [ 3.5990e-02],\n",
      "        [ 1.5654e-02],\n",
      "        [ 8.2753e-03],\n",
      "        [-2.0438e-02],\n",
      "        [ 1.4789e-04],\n",
      "        [ 1.1810e-02],\n",
      "        [-3.2591e-04],\n",
      "        [-1.1715e-02],\n",
      "        [ 3.8369e-03],\n",
      "        [-1.5619e-03],\n",
      "        [-4.6324e-03],\n",
      "        [-2.0825e-02],\n",
      "        [ 2.6798e-02],\n",
      "        [-4.5763e-03],\n",
      "        [-1.6945e-02],\n",
      "        [-1.3369e-03],\n",
      "        [ 9.5051e-03],\n",
      "        [ 2.8351e-02],\n",
      "        [ 9.8608e-03],\n",
      "        [ 3.9224e-02],\n",
      "        [-1.3259e-03],\n",
      "        [ 1.3669e-03],\n",
      "        [-1.0707e-02],\n",
      "        [-4.2131e-03],\n",
      "        [ 2.7399e-02],\n",
      "        [-1.6739e-02],\n",
      "        [ 4.8735e-03],\n",
      "        [-7.4365e-03],\n",
      "        [ 8.5270e-03],\n",
      "        [ 4.9587e-04],\n",
      "        [ 9.0459e-03],\n",
      "        [ 2.8231e-02]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gideon Price\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:538: UserWarning: Using a target size (torch.Size([109])) that is different to the input size (torch.Size([109, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "# Define the loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 5000\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    train_outputs = model(x_train)\n",
    "    train_loss = criterion(train_outputs, y_train)\n",
    "    train_loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_outputs = model(x_val)\n",
    "        val_loss = criterion(val_outputs, y_val)\n",
    "    \n",
    "    if (epoch + 1) % 500 == 0:\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Training Loss: {train_loss.item():.4f}, Validation Loss: {val_loss.item():.4f}')\n",
    "\n",
    "# Evaluate the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_outputs = model(x_test)\n",
    "    test_loss = criterion(test_outputs, y_test)\n",
    "    print(f'Test Loss: {test_loss.item():.4f}')\n",
    "\n",
    "# Make predictions\n",
    "with torch.no_grad():\n",
    "    predictions = model(x_test)\n",
    "    print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0385f6f7-de6e-45ca-9cdc-9b98c788e4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the dataset\n",
    "data_path = 'C:\\\\Users\\\\Gideon Price\\\\Downloads/Housing.csv'\n",
    "housing = pd.read_csv(data_path)\n",
    "housing.head()\n",
    "\n",
    "# Preprocessing data\n",
    "def binary(x):\n",
    "    return x.map({'no' : 0, 'yes' : 1})\n",
    "\n",
    "columns_to_convert = ['mainroad', 'guestroom', 'basement', 'hotwaterheating', 'prefarea', 'airconditioning']\n",
    "\n",
    "for column in columns_to_convert:\n",
    "    housing[column] = binary(housing[column])\n",
    "housing = housing.drop('furnishingstatus', axis=1)\n",
    "# Splitting the data into features and target\n",
    "x = housing[['area', 'bedrooms', 'bathrooms', 'stories', 'parking','mainroad', 'guestroom', 'basement', 'guestroom', 'hotwaterheating', 'basement', 'prefarea', 'airconditioning']].values\n",
    "y = housing['price'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4543b79d-09d2-4b6c-aae6-80ed71fd7255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 80/20 Train/Test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, train_size = 0.8, test_size=0.2, random_state=42)\n",
    "\n",
    "# Further split the training set into training and validation sets\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, train_size=0.8, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalizing the input data\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "x_val = scaler.transform(x_val)\n",
    "\n",
    "# Normalize output data\n",
    "y_train = scaler.fit_transform(y_train.reshape(-1, 1)).flatten()\n",
    "y_test = scaler.fit_transform(y_test.reshape(-1, 1)).flatten()\n",
    "y_val = scaler.transform(y_val.reshape(-1, 1)).flatten()\n",
    "\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "x_train = torch.tensor(x_train, dtype=torch.float32)\n",
    "x_test = torch.tensor(x_test, dtype=torch.float32)\n",
    "x_val = torch.tensor(x_val, dtype=torch.float32)\n",
    "y_train =  torch.tensor(y_train, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32)\n",
    "y_val = torch.tensor(y_val, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9f97260-fe9f-44b5-ab7c-5615e29c9b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add two more layers\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.hidden1 = nn.Linear(x_train.shape[1], 32)\n",
    "        self.hidden2 = nn.Linear(32, 64)\n",
    "        self.hidden3 = nn.Linear(64, 16)\n",
    "        self.output = nn.Linear(16, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.hidden1(x))\n",
    "        x = torch.relu(self.hidden2(x))\n",
    "        x = torch.relu(self.hidden3(x))\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n",
    "model = NeuralNetwork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d656c03-a332-4181-82b8-d1580c1ff42e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gideon Price\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:538: UserWarning: Using a target size (torch.Size([348])) that is different to the input size (torch.Size([348, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Gideon Price\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:538: UserWarning: Using a target size (torch.Size([88])) that is different to the input size (torch.Size([88, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [500/5000], Training Loss: 1.0000, Validation Loss: 0.6127\n",
      "Epoch [1000/5000], Training Loss: 1.0000, Validation Loss: 0.6127\n",
      "Epoch [1500/5000], Training Loss: 1.0000, Validation Loss: 0.6127\n",
      "Epoch [2000/5000], Training Loss: 1.0000, Validation Loss: 0.6127\n",
      "Epoch [2500/5000], Training Loss: 1.0000, Validation Loss: 0.6127\n",
      "Epoch [3000/5000], Training Loss: 1.0000, Validation Loss: 0.6127\n",
      "Epoch [3500/5000], Training Loss: 1.0000, Validation Loss: 0.6126\n",
      "Epoch [4000/5000], Training Loss: 1.0000, Validation Loss: 0.6127\n",
      "Epoch [4500/5000], Training Loss: 1.0000, Validation Loss: 0.6127\n",
      "Epoch [5000/5000], Training Loss: 1.0000, Validation Loss: 0.6127\n",
      "Test Loss: 1.0000\n",
      "tensor([[ 1.3656e-03],\n",
      "        [ 1.2268e-04],\n",
      "        [ 1.5344e-05],\n",
      "        [ 1.3089e-04],\n",
      "        [-8.5682e-06],\n",
      "        [ 1.1229e-04],\n",
      "        [-1.8464e-04],\n",
      "        [ 5.1699e-04],\n",
      "        [ 2.1157e-03],\n",
      "        [-6.2138e-06],\n",
      "        [-5.3014e-04],\n",
      "        [ 7.0445e-06],\n",
      "        [ 8.2085e-04],\n",
      "        [-4.2971e-04],\n",
      "        [-1.6550e-04],\n",
      "        [-7.6344e-03],\n",
      "        [ 1.3296e-03],\n",
      "        [ 2.7137e-04],\n",
      "        [-7.4271e-04],\n",
      "        [ 1.0202e-05],\n",
      "        [-3.9120e-03],\n",
      "        [-3.7129e-03],\n",
      "        [-1.5263e-05],\n",
      "        [ 5.4753e-04],\n",
      "        [-2.4171e-03],\n",
      "        [-5.3368e-03],\n",
      "        [ 1.7455e-04],\n",
      "        [ 2.7332e-03],\n",
      "        [-6.0536e-03],\n",
      "        [ 1.9018e-06],\n",
      "        [ 1.0536e-03],\n",
      "        [ 7.6860e-04],\n",
      "        [ 1.6936e-04],\n",
      "        [-4.5181e-04],\n",
      "        [ 7.0654e-05],\n",
      "        [ 8.1569e-04],\n",
      "        [ 4.1627e-03],\n",
      "        [ 1.2509e-03],\n",
      "        [ 3.0147e-04],\n",
      "        [ 2.7093e-04],\n",
      "        [ 8.4126e-05],\n",
      "        [-2.2902e-04],\n",
      "        [ 2.1602e-04],\n",
      "        [ 5.0627e-06],\n",
      "        [ 1.4201e-05],\n",
      "        [ 2.1437e-04],\n",
      "        [-3.5018e-06],\n",
      "        [ 9.1706e-04],\n",
      "        [ 3.2352e-04],\n",
      "        [-2.9700e-05],\n",
      "        [-2.2367e-04],\n",
      "        [ 8.1044e-06],\n",
      "        [-7.2015e-05],\n",
      "        [ 6.6066e-04],\n",
      "        [ 8.2690e-04],\n",
      "        [ 2.6371e-05],\n",
      "        [-5.4633e-03],\n",
      "        [ 5.2132e-04],\n",
      "        [ 8.1128e-04],\n",
      "        [-3.4422e-06],\n",
      "        [-4.1922e-04],\n",
      "        [ 6.6191e-04],\n",
      "        [-9.5053e-04],\n",
      "        [-1.1361e-03],\n",
      "        [ 2.3152e-04],\n",
      "        [ 8.1606e-04],\n",
      "        [-8.1496e-03],\n",
      "        [-1.9534e-05],\n",
      "        [-1.0986e-02],\n",
      "        [-2.9664e-03],\n",
      "        [-1.2114e-03],\n",
      "        [-1.7310e-03],\n",
      "        [ 1.7611e-04],\n",
      "        [-8.8645e-04],\n",
      "        [-3.9214e-04],\n",
      "        [ 1.6527e-03],\n",
      "        [ 3.2702e-04],\n",
      "        [-1.0839e-02],\n",
      "        [-1.8267e-03],\n",
      "        [-1.3334e-02],\n",
      "        [-4.2603e-03],\n",
      "        [-7.6260e-05],\n",
      "        [ 1.7259e-03],\n",
      "        [-4.6488e-04],\n",
      "        [ 2.5566e-03],\n",
      "        [-1.1983e-03],\n",
      "        [-8.5505e-05],\n",
      "        [ 5.3629e-05],\n",
      "        [-3.7853e-03],\n",
      "        [ 4.8464e-03],\n",
      "        [ 3.2175e-03],\n",
      "        [-3.9767e-03],\n",
      "        [-1.5453e-04],\n",
      "        [ 4.4715e-03],\n",
      "        [ 4.5131e-03],\n",
      "        [-7.2121e-04],\n",
      "        [-2.6263e-03],\n",
      "        [ 1.2797e-04],\n",
      "        [ 3.5867e-04],\n",
      "        [ 4.7648e-03],\n",
      "        [ 6.2755e-04],\n",
      "        [-3.2011e-03],\n",
      "        [ 2.7031e-05],\n",
      "        [-4.2368e-03],\n",
      "        [-1.2946e-03],\n",
      "        [ 2.8721e-03],\n",
      "        [-1.4342e-07],\n",
      "        [-1.9069e-03],\n",
      "        [-2.0509e-03]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gideon Price\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:538: UserWarning: Using a target size (torch.Size([109])) that is different to the input size (torch.Size([109, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "# Define the loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 5000\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    train_outputs = model(x_train)\n",
    "    train_loss = criterion(train_outputs, y_train)\n",
    "    train_loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_outputs = model(x_val)\n",
    "        val_loss = criterion(val_outputs, y_val)\n",
    "    \n",
    "    if (epoch + 1) % 500 == 0:\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Training Loss: {train_loss.item():.4f}, Validation Loss: {val_loss.item():.4f}')\n",
    "\n",
    "# Evaluate the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_outputs = model(x_test)\n",
    "    test_loss = criterion(test_outputs, y_test)\n",
    "    print(f'Test Loss: {test_loss.item():.4f}')\n",
    "\n",
    "# Make predictions\n",
    "with torch.no_grad():\n",
    "    predictions2 = model(x_test)\n",
    "    print(predictions2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd5b61b1-d239-4d24-8c3f-f8c3a8898549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "'''Question 2'''\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "\n",
    "# Transformations for data normalization\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Load CIFAR-10 dataset\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size=100, shuffle=True, num_workers=2)\n",
    "testloader = DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10d85642-aa85-42f5-a945-d8d0199c08e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullyConnectedNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FullyConnectedNN, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.hidden = nn.Linear(3 * 32 * 32, 512)  # CIFAR-10 images are 32x32x3\n",
    "        self.output = nn.Linear(512, 10)  # 10 classes for CIFAR-10\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = torch.relu(self.hidden(x))\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n",
    "model = FullyConnectedNN()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d72ad22b-c81f-4296-9a88-cc603eee90c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 1.6451, Epoch Time: 27.94 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()  # Suitable for multi-class classification\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 10\n",
    "total_start_time = time.time()  # Record the total start time\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_start_time = time.time()  # Record the start time for this epoch\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for inputs, labels in trainloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    # Calculate and print the duration for the epoch\n",
    "    epoch_end_time = time.time()\n",
    "    epoch_duration = epoch_end_time - epoch_start_time\n",
    "    if (epoch + 1) % 1 == 0:\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {running_loss / len(trainloader):.4f}, Epoch Time: {epoch_duration:.2f} seconds\")\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in testloader:\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'Accuracy of the network: {100 * correct / total:.2f}%')\n",
    "# Calculate and print the total training duration\n",
    "total_end_time = time.time()\n",
    "total_duration = total_end_time - total_start_time\n",
    "print(f\"Total Training Time: {total_duration:.2f} seconds\")\n",
    "\n",
    "\n",
    "print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce54ea66-cf00-4301-aff2-26d0a7c6209b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "\n",
    "# Transformations for data normalization\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Load CIFAR-10 dataset\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size=100, shuffle=True, num_workers=2)\n",
    "testloader = DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bfdb028e-9c92-4b04-b21d-cad4b43f7d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(32 * 32 * 3, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(512, 256),  # Additional hidden layer 1\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256, 128),  # Additional hidden layer 2\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128, 10)\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6cbc18e-dc71-41d5-b89f-736d55510baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''criterion = nn.CrossEntropyLoss()  # Suitable for multi-class classification\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 10\n",
    "total_start_time = time.time()  # Record the total start time\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_start_time = time.time()  # Record the start time for this epoch\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for inputs, labels in trainloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    # Calculate and print the duration for the epoch\n",
    "    epoch_end_time = time.time()\n",
    "    epoch_duration = epoch_end_time - epoch_start_time\n",
    "    if (epoch + 1) % 1 == 0:\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {running_loss / len(trainloader):.4f}, Epoch Time: {epoch_duration:.2f} seconds\")\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in testloader:\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'Accuracy of the network: {100 * correct / total:.2f}%')\n",
    "# Calculate and print the total training duration\n",
    "total_end_time = time.time()\n",
    "total_duration = total_end_time - total_start_time\n",
    "print(f\"Total Training Time: {total_duration:.2f} seconds\")\n",
    "\n",
    "\n",
    "print('Finished Training')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22f8b985-ab1d-45a4-b484-97087a11024b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/300], Training Loss: 0.2116, Validation Loss: 3.2289, Accuracy: 53.16%, Epoch Time: 35.09 seconds\n",
      "Epoch [60/300], Training Loss: 0.1413, Validation Loss: 4.6923, Accuracy: 52.73%, Epoch Time: 34.91 seconds\n",
      "Epoch [90/300], Training Loss: 0.0854, Validation Loss: 5.5782, Accuracy: 52.67%, Epoch Time: 35.23 seconds\n",
      "Epoch [120/300], Training Loss: 0.0809, Validation Loss: 6.2655, Accuracy: 53.38%, Epoch Time: 34.94 seconds\n",
      "Epoch [150/300], Training Loss: 0.1127, Validation Loss: 6.5815, Accuracy: 52.69%, Epoch Time: 35.65 seconds\n",
      "Epoch [180/300], Training Loss: 0.0712, Validation Loss: 7.6922, Accuracy: 53.09%, Epoch Time: 36.20 seconds\n",
      "Epoch [210/300], Training Loss: 0.0766, Validation Loss: 8.4197, Accuracy: 52.43%, Epoch Time: 36.59 seconds\n",
      "Epoch [240/300], Training Loss: 0.0674, Validation Loss: 9.4571, Accuracy: 52.93%, Epoch Time: 37.33 seconds\n",
      "Epoch [270/300], Training Loss: 0.0697, Validation Loss: 10.3845, Accuracy: 52.91%, Epoch Time: 38.21 seconds\n",
      "Epoch [300/300], Training Loss: 0.0729, Validation Loss: 10.6648, Accuracy: 52.38%, Epoch Time: 38.53 seconds\n",
      "Total Training Time: 10857.60 seconds\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 300\n",
    "total_start_time = time.time()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_start_time = time.time()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    model.train()\n",
    "    for inputs, labels in trainloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    training_loss = running_loss / len(trainloader)\n",
    "    \n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in testloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    validation_loss = val_loss / len(testloader)\n",
    "    accuracy = 100 * correct / total\n",
    "\n",
    "    epoch_end_time = time.time()\n",
    "    epoch_duration = epoch_end_time - epoch_start_time\n",
    "    \n",
    "    if (epoch + 1) % 30 == 0:\n",
    "        # Show training and validation loss to check for overfitting\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Training Loss: {training_loss:.4f}, Validation Loss: {validation_loss:.4f}, Accuracy: {accuracy:.2f}%, Epoch Time: {epoch_duration:.2f} seconds')\n",
    "\n",
    "total_end_time = time.time()\n",
    "total_duration = total_end_time - total_start_time\n",
    "print(f'Total Training Time: {total_duration:.2f} seconds')\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797707d9-dd02-4fb5-97ec-e4914a08e5f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
